{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Генерация новостного текста на английском языке с использованием RNN**\n",
        "\n",
        "\n",
        "Или пример как не надо создавать фейковые новости"
      ],
      "metadata": {
        "id": "lERgm_QuiAsI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7Z80O58MRFS",
        "outputId": "89404b24-4724-43c2-860d-382395438e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ugHm497yR6hp"
      },
      "outputs": [],
      "source": [
        "# Импорт библиотек\n",
        "import re\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для обучения модели я собрала датасет из 500 новостных статей от BBC и The Guardian"
      ],
      "metadata": {
        "id": "7iHlFa3_K-VU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k5anGZoMyHO",
        "outputId": "312cf314-c162-440b-9433-f30ba8b44cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BBC: 1 статей собрано.\n",
            "BBC: 2 статей собрано.\n",
            "BBC: 3 статей собрано.\n",
            "BBC: 4 статей собрано.\n",
            "BBC: 5 статей собрано.\n",
            "BBC: 6 статей собрано.\n",
            "BBC: 7 статей собрано.\n",
            "BBC: 8 статей собрано.\n",
            "BBC: 9 статей собрано.\n",
            "BBC: 10 статей собрано.\n",
            "BBC: 11 статей собрано.\n",
            "BBC: 12 статей собрано.\n",
            "BBC: 13 статей собрано.\n",
            "BBC: 14 статей собрано.\n",
            "BBC: 15 статей собрано.\n",
            "BBC: 16 статей собрано.\n",
            "BBC: 17 статей собрано.\n",
            "BBC: 18 статей собрано.\n",
            "BBC: 19 статей собрано.\n",
            "BBC: 20 статей собрано.\n",
            "BBC: 21 статей собрано.\n",
            "BBC: 22 статей собрано.\n",
            "BBC: 23 статей собрано.\n",
            "BBC: 24 статей собрано.\n",
            "BBC: 25 статей собрано.\n",
            "BBC: 26 статей собрано.\n",
            "BBC: 27 статей собрано.\n",
            "BBC: 28 статей собрано.\n",
            "BBC: 29 статей собрано.\n",
            "BBC: 30 статей собрано.\n",
            "BBC: 31 статей собрано.\n",
            "BBC: 32 статей собрано.\n",
            "BBC: 33 статей собрано.\n",
            "BBC: 34 статей собрано.\n",
            "BBC: 35 статей собрано.\n",
            "BBC: 36 статей собрано.\n",
            "BBC: 37 статей собрано.\n",
            "BBC: 38 статей собрано.\n",
            "BBC: 39 статей собрано.\n",
            "BBC: 40 статей собрано.\n",
            "BBC: 41 статей собрано.\n",
            "BBC: 42 статей собрано.\n",
            "BBC: 43 статей собрано.\n",
            "BBC: 44 статей собрано.\n",
            "BBC: 45 статей собрано.\n",
            "BBC: 46 статей собрано.\n",
            "BBC: 47 статей собрано.\n",
            "BBC: 48 статей собрано.\n",
            "BBC: 49 статей собрано.\n",
            "BBC: 50 статей собрано.\n",
            "BBC: 51 статей собрано.\n",
            "BBC: 52 статей собрано.\n",
            "BBC: 53 статей собрано.\n",
            "BBC: 54 статей собрано.\n",
            "BBC: 55 статей собрано.\n",
            "BBC: 56 статей собрано.\n",
            "BBC: 57 статей собрано.\n",
            "BBC: 58 статей собрано.\n",
            "BBC: 59 статей собрано.\n",
            "BBC: 60 статей собрано.\n",
            "BBC: 61 статей собрано.\n",
            "BBC: 62 статей собрано.\n",
            "BBC: 63 статей собрано.\n",
            "BBC: 64 статей собрано.\n",
            "BBC: 65 статей собрано.\n",
            "BBC: 66 статей собрано.\n",
            "BBC: 67 статей собрано.\n",
            "BBC: 68 статей собрано.\n",
            "BBC: 69 статей собрано.\n",
            "BBC: 70 статей собрано.\n",
            "BBC: 71 статей собрано.\n",
            "BBC: 72 статей собрано.\n",
            "BBC: 73 статей собрано.\n",
            "BBC: 74 статей собрано.\n",
            "BBC: 75 статей собрано.\n",
            "BBC: 76 статей собрано.\n",
            "BBC: 77 статей собрано.\n",
            "BBC: 78 статей собрано.\n",
            "BBC: 79 статей собрано.\n",
            "BBC: 80 статей собрано.\n",
            "BBC: 81 статей собрано.\n",
            "BBC: 82 статей собрано.\n",
            "BBC: 83 статей собрано.\n",
            "BBC: 84 статей собрано.\n",
            "BBC: 85 статей собрано.\n",
            "BBC: 86 статей собрано.\n",
            "BBC: 87 статей собрано.\n",
            "BBC: 88 статей собрано.\n",
            "BBC: 89 статей собрано.\n",
            "BBC: 90 статей собрано.\n",
            "BBC: 91 статей собрано.\n",
            "BBC: 92 статей собрано.\n",
            "BBC: 93 статей собрано.\n",
            "BBC: 94 статей собрано.\n",
            "BBC: 95 статей собрано.\n",
            "BBC: 96 статей собрано.\n",
            "BBC: 97 статей собрано.\n",
            "BBC: 98 статей собрано.\n",
            "BBC: 99 статей собрано.\n",
            "BBC: 100 статей собрано.\n",
            "BBC: 101 статей собрано.\n",
            "BBC: 102 статей собрано.\n",
            "BBC: 103 статей собрано.\n",
            "BBC: 104 статей собрано.\n",
            "BBC: 105 статей собрано.\n",
            "BBC: 106 статей собрано.\n",
            "BBC: 107 статей собрано.\n",
            "BBC: 108 статей собрано.\n",
            "BBC: 109 статей собрано.\n",
            "BBC: 110 статей собрано.\n",
            "BBC: 111 статей собрано.\n",
            "BBC: 112 статей собрано.\n",
            "BBC: 113 статей собрано.\n",
            "BBC: 114 статей собрано.\n",
            "BBC: 115 статей собрано.\n",
            "BBC: 116 статей собрано.\n",
            "BBC: 117 статей собрано.\n",
            "BBC: 118 статей собрано.\n",
            "BBC: 119 статей собрано.\n",
            "BBC: 120 статей собрано.\n",
            "BBC: 121 статей собрано.\n",
            "BBC: 122 статей собрано.\n",
            "BBC: 123 статей собрано.\n",
            "BBC: 124 статей собрано.\n",
            "BBC: 125 статей собрано.\n",
            "BBC: 126 статей собрано.\n",
            "BBC: 127 статей собрано.\n",
            "BBC: 128 статей собрано.\n",
            "BBC: 129 статей собрано.\n",
            "BBC: 130 статей собрано.\n",
            "BBC: 131 статей собрано.\n",
            "BBC: 132 статей собрано.\n",
            "BBC: 133 статей собрано.\n",
            "BBC: 134 статей собрано.\n",
            "BBC: 135 статей собрано.\n",
            "BBC: 136 статей собрано.\n",
            "BBC: 137 статей собрано.\n",
            "BBC: 138 статей собрано.\n",
            "BBC: 139 статей собрано.\n",
            "BBC: 140 статей собрано.\n",
            "BBC: 141 статей собрано.\n",
            "BBC: 142 статей собрано.\n",
            "BBC: 143 статей собрано.\n",
            "BBC: 144 статей собрано.\n",
            "BBC: 145 статей собрано.\n",
            "BBC: 146 статей собрано.\n",
            "BBC: 147 статей собрано.\n",
            "BBC: 148 статей собрано.\n",
            "BBC: 149 статей собрано.\n",
            "BBC: 150 статей собрано.\n",
            "BBC: 151 статей собрано.\n",
            "BBC: 152 статей собрано.\n",
            "BBC: 153 статей собрано.\n",
            "BBC: 154 статей собрано.\n",
            "BBC: 155 статей собрано.\n",
            "BBC: 156 статей собрано.\n",
            "BBC: 157 статей собрано.\n",
            "BBC: 158 статей собрано.\n",
            "BBC: 159 статей собрано.\n",
            "BBC: 160 статей собрано.\n",
            "BBC: 161 статей собрано.\n",
            "BBC: 162 статей собрано.\n",
            "BBC: 163 статей собрано.\n",
            "BBC: 164 статей собрано.\n",
            "BBC: 165 статей собрано.\n",
            "BBC: 166 статей собрано.\n",
            "BBC: 167 статей собрано.\n",
            "BBC: 168 статей собрано.\n",
            "BBC: 169 статей собрано.\n",
            "BBC: 170 статей собрано.\n",
            "BBC: 171 статей собрано.\n",
            "BBC: 172 статей собрано.\n",
            "BBC: 173 статей собрано.\n",
            "BBC: 174 статей собрано.\n",
            "BBC: 175 статей собрано.\n",
            "BBC: 176 статей собрано.\n",
            "BBC: 177 статей собрано.\n",
            "BBC: 178 статей собрано.\n",
            "BBC: 179 статей собрано.\n",
            "BBC: 180 статей собрано.\n",
            "BBC: 181 статей собрано.\n",
            "BBC: 182 статей собрано.\n",
            "BBC: 183 статей собрано.\n",
            "BBC: 184 статей собрано.\n",
            "BBC: 185 статей собрано.\n",
            "BBC: 186 статей собрано.\n",
            "BBC: 187 статей собрано.\n",
            "BBC: 188 статей собрано.\n",
            "BBC: 189 статей собрано.\n",
            "BBC: 190 статей собрано.\n",
            "BBC: 191 статей собрано.\n",
            "BBC: 192 статей собрано.\n",
            "BBC: 193 статей собрано.\n",
            "BBC: 194 статей собрано.\n",
            "BBC: 195 статей собрано.\n",
            "BBC: 196 статей собрано.\n",
            "BBC: 197 статей собрано.\n",
            "BBC: 198 статей собрано.\n",
            "BBC: 199 статей собрано.\n",
            "BBC: 200 статей собрано.\n",
            "BBC: 201 статей собрано.\n",
            "BBC: 202 статей собрано.\n",
            "BBC: 203 статей собрано.\n",
            "BBC: 204 статей собрано.\n",
            "BBC: 205 статей собрано.\n",
            "BBC: 206 статей собрано.\n",
            "BBC: 207 статей собрано.\n",
            "BBC: 208 статей собрано.\n",
            "BBC: 209 статей собрано.\n",
            "BBC: 210 статей собрано.\n",
            "BBC: 211 статей собрано.\n",
            "BBC: 212 статей собрано.\n",
            "BBC: 213 статей собрано.\n",
            "BBC: 214 статей собрано.\n",
            "BBC: 215 статей собрано.\n",
            "BBC: 216 статей собрано.\n",
            "BBC: 217 статей собрано.\n",
            "BBC: 218 статей собрано.\n",
            "BBC: 219 статей собрано.\n",
            "BBC: 220 статей собрано.\n",
            "BBC: 221 статей собрано.\n",
            "BBC: 222 статей собрано.\n",
            "BBC: 223 статей собрано.\n",
            "BBC: 224 статей собрано.\n",
            "BBC: 225 статей собрано.\n",
            "BBC: 226 статей собрано.\n",
            "BBC: 227 статей собрано.\n",
            "BBC: 228 статей собрано.\n",
            "BBC: 229 статей собрано.\n",
            "BBC: 230 статей собрано.\n",
            "BBC: 231 статей собрано.\n",
            "BBC: 232 статей собрано.\n",
            "BBC: 233 статей собрано.\n",
            "BBC: 234 статей собрано.\n",
            "BBC: 235 статей собрано.\n",
            "BBC: 236 статей собрано.\n",
            "BBC: 237 статей собрано.\n",
            "BBC: 238 статей собрано.\n",
            "BBC: 239 статей собрано.\n",
            "BBC: 240 статей собрано.\n",
            "BBC: 241 статей собрано.\n",
            "BBC: 242 статей собрано.\n",
            "BBC: 243 статей собрано.\n",
            "BBC: 244 статей собрано.\n",
            "BBC: 245 статей собрано.\n",
            "BBC: 246 статей собрано.\n",
            "BBC: 247 статей собрано.\n",
            "BBC: 248 статей собрано.\n",
            "BBC: 249 статей собрано.\n",
            "BBC: 250 статей собрано.\n"
          ]
        }
      ],
      "source": [
        "bbc_rss_urls = [\n",
        "    \"https://feeds.bbci.co.uk/news/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/world/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/uk/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/business/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/technology/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/science_and_environment/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/health/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/education/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/entertainment_and_arts/rss.xml\",\n",
        "    \"https://feeds.bbci.co.uk/news/politics/rss.xml\"\n",
        "]\n",
        "\n",
        "def get_bbc_links(rss_url):\n",
        "    response = requests.get(rss_url)\n",
        "    soup = BeautifulSoup(response.content, features=\"xml\")\n",
        "    return [item.link.text for item in soup.find_all(\"item\")]\n",
        "\n",
        "def get_bbc_article_text(url):\n",
        "    try:\n",
        "        r = requests.get(url)\n",
        "        soup = BeautifulSoup(r.content, 'html.parser')\n",
        "        article = soup.find('article')\n",
        "        if article:\n",
        "            paragraphs = article.find_all('p')\n",
        "            return ' '.join(p.text for p in paragraphs)\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "bbc_articles = []\n",
        "seen_urls = set()\n",
        "\n",
        "for rss_url in bbc_rss_urls:\n",
        "    links = get_bbc_links(rss_url)\n",
        "    for link in links:\n",
        "        if link in seen_urls or len(bbc_articles) >= 250:\n",
        "            continue\n",
        "        seen_urls.add(link)\n",
        "        text = get_bbc_article_text(link)\n",
        "        if text and len(text) > 300:\n",
        "            bbc_articles.append(text)\n",
        "            print(f\"BBC: {len(bbc_articles)} статей собрано.\")\n",
        "        time.sleep(1)\n",
        "\n",
        "# Сохраняем\n",
        "with open(\"bbc_articles.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for article in bbc_articles:\n",
        "        f.write(article + \"\\n\" + \"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNaQtsT7OPWH",
        "outputId": "9ab62c8e-f0ba-4db9-dfca-2e1a6cfb7947"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Guardian: 1 статей собрано.\n",
            "Guardian: 2 статей собрано.\n",
            "Guardian: 3 статей собрано.\n",
            "Guardian: 4 статей собрано.\n",
            "Guardian: 5 статей собрано.\n",
            "Guardian: 6 статей собрано.\n",
            "Guardian: 7 статей собрано.\n",
            "Guardian: 8 статей собрано.\n",
            "Guardian: 9 статей собрано.\n",
            "Guardian: 10 статей собрано.\n",
            "Guardian: 11 статей собрано.\n",
            "Guardian: 12 статей собрано.\n",
            "Guardian: 13 статей собрано.\n",
            "Guardian: 14 статей собрано.\n",
            "Guardian: 15 статей собрано.\n",
            "Guardian: 16 статей собрано.\n",
            "Guardian: 17 статей собрано.\n",
            "Guardian: 18 статей собрано.\n",
            "Guardian: 19 статей собрано.\n",
            "Guardian: 20 статей собрано.\n",
            "Guardian: 21 статей собрано.\n",
            "Guardian: 22 статей собрано.\n",
            "Guardian: 23 статей собрано.\n",
            "Guardian: 24 статей собрано.\n",
            "Guardian: 25 статей собрано.\n",
            "Guardian: 26 статей собрано.\n",
            "Guardian: 27 статей собрано.\n",
            "Guardian: 28 статей собрано.\n",
            "Guardian: 29 статей собрано.\n",
            "Guardian: 30 статей собрано.\n",
            "Guardian: 31 статей собрано.\n",
            "Guardian: 32 статей собрано.\n",
            "Guardian: 33 статей собрано.\n",
            "Guardian: 34 статей собрано.\n",
            "Guardian: 35 статей собрано.\n",
            "Guardian: 36 статей собрано.\n",
            "Guardian: 37 статей собрано.\n",
            "Guardian: 38 статей собрано.\n",
            "Guardian: 39 статей собрано.\n",
            "Guardian: 40 статей собрано.\n",
            "Guardian: 41 статей собрано.\n",
            "Guardian: 42 статей собрано.\n",
            "Guardian: 43 статей собрано.\n",
            "Guardian: 44 статей собрано.\n",
            "Guardian: 45 статей собрано.\n",
            "Guardian: 46 статей собрано.\n",
            "Guardian: 47 статей собрано.\n",
            "Guardian: 48 статей собрано.\n",
            "Guardian: 49 статей собрано.\n",
            "Guardian: 50 статей собрано.\n",
            "Guardian: 51 статей собрано.\n",
            "Guardian: 52 статей собрано.\n",
            "Guardian: 53 статей собрано.\n",
            "Guardian: 54 статей собрано.\n",
            "Guardian: 55 статей собрано.\n",
            "Guardian: 56 статей собрано.\n",
            "Guardian: 57 статей собрано.\n",
            "Guardian: 58 статей собрано.\n",
            "Guardian: 59 статей собрано.\n",
            "Guardian: 60 статей собрано.\n",
            "Guardian: 61 статей собрано.\n",
            "Guardian: 62 статей собрано.\n",
            "Guardian: 63 статей собрано.\n",
            "Guardian: 64 статей собрано.\n",
            "Guardian: 65 статей собрано.\n",
            "Guardian: 66 статей собрано.\n",
            "Guardian: 67 статей собрано.\n",
            "Guardian: 68 статей собрано.\n",
            "Guardian: 69 статей собрано.\n",
            "Guardian: 70 статей собрано.\n",
            "Guardian: 71 статей собрано.\n",
            "Guardian: 72 статей собрано.\n",
            "Guardian: 73 статей собрано.\n",
            "Guardian: 74 статей собрано.\n",
            "Guardian: 75 статей собрано.\n",
            "Guardian: 76 статей собрано.\n",
            "Guardian: 77 статей собрано.\n",
            "Guardian: 78 статей собрано.\n",
            "Guardian: 79 статей собрано.\n",
            "Guardian: 80 статей собрано.\n",
            "Guardian: 81 статей собрано.\n",
            "Guardian: 82 статей собрано.\n",
            "Guardian: 83 статей собрано.\n",
            "Guardian: 84 статей собрано.\n",
            "Guardian: 85 статей собрано.\n",
            "Guardian: 86 статей собрано.\n",
            "Guardian: 87 статей собрано.\n",
            "Guardian: 88 статей собрано.\n",
            "Guardian: 89 статей собрано.\n",
            "Guardian: 90 статей собрано.\n",
            "Guardian: 91 статей собрано.\n",
            "Guardian: 92 статей собрано.\n",
            "Guardian: 93 статей собрано.\n",
            "Guardian: 94 статей собрано.\n",
            "Guardian: 95 статей собрано.\n",
            "Guardian: 96 статей собрано.\n",
            "Guardian: 97 статей собрано.\n",
            "Guardian: 98 статей собрано.\n",
            "Guardian: 99 статей собрано.\n",
            "Guardian: 100 статей собрано.\n",
            "Guardian: 101 статей собрано.\n",
            "Guardian: 102 статей собрано.\n",
            "Guardian: 103 статей собрано.\n",
            "Guardian: 104 статей собрано.\n",
            "Guardian: 105 статей собрано.\n",
            "Guardian: 106 статей собрано.\n",
            "Guardian: 107 статей собрано.\n",
            "Guardian: 108 статей собрано.\n",
            "Guardian: 109 статей собрано.\n",
            "Guardian: 110 статей собрано.\n",
            "Guardian: 111 статей собрано.\n",
            "Guardian: 112 статей собрано.\n",
            "Guardian: 113 статей собрано.\n",
            "Guardian: 114 статей собрано.\n",
            "Guardian: 115 статей собрано.\n",
            "Guardian: 116 статей собрано.\n",
            "Guardian: 117 статей собрано.\n",
            "Guardian: 118 статей собрано.\n",
            "Guardian: 119 статей собрано.\n",
            "Guardian: 120 статей собрано.\n",
            "Guardian: 121 статей собрано.\n",
            "Guardian: 122 статей собрано.\n",
            "Guardian: 123 статей собрано.\n",
            "Guardian: 124 статей собрано.\n",
            "Guardian: 125 статей собрано.\n",
            "Guardian: 126 статей собрано.\n",
            "Guardian: 127 статей собрано.\n",
            "Guardian: 128 статей собрано.\n",
            "Guardian: 129 статей собрано.\n",
            "Guardian: 130 статей собрано.\n",
            "Guardian: 131 статей собрано.\n",
            "Guardian: 132 статей собрано.\n",
            "Guardian: 133 статей собрано.\n",
            "Guardian: 134 статей собрано.\n",
            "Guardian: 135 статей собрано.\n",
            "Guardian: 136 статей собрано.\n",
            "Guardian: 137 статей собрано.\n",
            "Guardian: 138 статей собрано.\n",
            "Guardian: 139 статей собрано.\n",
            "Guardian: 140 статей собрано.\n",
            "Guardian: 141 статей собрано.\n",
            "Guardian: 142 статей собрано.\n",
            "Guardian: 143 статей собрано.\n",
            "Guardian: 144 статей собрано.\n",
            "Guardian: 145 статей собрано.\n",
            "Guardian: 146 статей собрано.\n",
            "Guardian: 147 статей собрано.\n",
            "Guardian: 148 статей собрано.\n",
            "Guardian: 149 статей собрано.\n",
            "Guardian: 150 статей собрано.\n",
            "Guardian: 151 статей собрано.\n",
            "Guardian: 152 статей собрано.\n",
            "Guardian: 153 статей собрано.\n",
            "Guardian: 154 статей собрано.\n",
            "Guardian: 155 статей собрано.\n",
            "Guardian: 156 статей собрано.\n",
            "Guardian: 157 статей собрано.\n",
            "Guardian: 158 статей собрано.\n",
            "Guardian: 159 статей собрано.\n",
            "Guardian: 160 статей собрано.\n",
            "Guardian: 161 статей собрано.\n",
            "Guardian: 162 статей собрано.\n",
            "Guardian: 163 статей собрано.\n",
            "Guardian: 164 статей собрано.\n",
            "Guardian: 165 статей собрано.\n",
            "Guardian: 166 статей собрано.\n",
            "Guardian: 167 статей собрано.\n",
            "Guardian: 168 статей собрано.\n",
            "Guardian: 169 статей собрано.\n",
            "Guardian: 170 статей собрано.\n",
            "Guardian: 171 статей собрано.\n",
            "Guardian: 172 статей собрано.\n",
            "Guardian: 173 статей собрано.\n",
            "Guardian: 174 статей собрано.\n",
            "Guardian: 175 статей собрано.\n",
            "Guardian: 176 статей собрано.\n",
            "Guardian: 177 статей собрано.\n",
            "Guardian: 178 статей собрано.\n",
            "Guardian: 179 статей собрано.\n",
            "Guardian: 180 статей собрано.\n",
            "Guardian: 181 статей собрано.\n",
            "Guardian: 182 статей собрано.\n",
            "Guardian: 183 статей собрано.\n",
            "Guardian: 184 статей собрано.\n",
            "Guardian: 185 статей собрано.\n",
            "Guardian: 186 статей собрано.\n",
            "Guardian: 187 статей собрано.\n",
            "Guardian: 188 статей собрано.\n",
            "Guardian: 189 статей собрано.\n",
            "Guardian: 190 статей собрано.\n",
            "Guardian: 191 статей собрано.\n",
            "Guardian: 192 статей собрано.\n",
            "Guardian: 193 статей собрано.\n",
            "Guardian: 194 статей собрано.\n",
            "Guardian: 195 статей собрано.\n",
            "Guardian: 196 статей собрано.\n",
            "Guardian: 197 статей собрано.\n",
            "Guardian: 198 статей собрано.\n",
            "Guardian: 199 статей собрано.\n",
            "Guardian: 200 статей собрано.\n",
            "Guardian: 201 статей собрано.\n",
            "Guardian: 202 статей собрано.\n",
            "Guardian: 203 статей собрано.\n",
            "Guardian: 204 статей собрано.\n",
            "Guardian: 205 статей собрано.\n",
            "Guardian: 206 статей собрано.\n",
            "Guardian: 207 статей собрано.\n",
            "Guardian: 208 статей собрано.\n",
            "Guardian: 209 статей собрано.\n",
            "Guardian: 210 статей собрано.\n",
            "Guardian: 211 статей собрано.\n",
            "Guardian: 212 статей собрано.\n",
            "Guardian: 213 статей собрано.\n",
            "Guardian: 214 статей собрано.\n",
            "Guardian: 215 статей собрано.\n",
            "Guardian: 216 статей собрано.\n",
            "Guardian: 217 статей собрано.\n",
            "Guardian: 218 статей собрано.\n",
            "Guardian: 219 статей собрано.\n",
            "Guardian: 220 статей собрано.\n",
            "Guardian: 221 статей собрано.\n",
            "Guardian: 222 статей собрано.\n",
            "Guardian: 223 статей собрано.\n",
            "Guardian: 224 статей собрано.\n",
            "Guardian: 225 статей собрано.\n",
            "Guardian: 226 статей собрано.\n",
            "Guardian: 227 статей собрано.\n",
            "Guardian: 228 статей собрано.\n",
            "Guardian: 229 статей собрано.\n",
            "Guardian: 230 статей собрано.\n",
            "Guardian: 231 статей собрано.\n",
            "Guardian: 232 статей собрано.\n",
            "Guardian: 233 статей собрано.\n",
            "Guardian: 234 статей собрано.\n",
            "Guardian: 235 статей собрано.\n",
            "Guardian: 236 статей собрано.\n",
            "Guardian: 237 статей собрано.\n",
            "Guardian: 238 статей собрано.\n",
            "Guardian: 239 статей собрано.\n",
            "Guardian: 240 статей собрано.\n",
            "Guardian: 241 статей собрано.\n",
            "Guardian: 242 статей собрано.\n",
            "Guardian: 243 статей собрано.\n",
            "Guardian: 244 статей собрано.\n",
            "Guardian: 245 статей собрано.\n",
            "Guardian: 246 статей собрано.\n",
            "Guardian: 247 статей собрано.\n",
            "Guardian: 248 статей собрано.\n",
            "Guardian: 249 статей собрано.\n",
            "Guardian: 250 статей собрано.\n"
          ]
        }
      ],
      "source": [
        "API_KEY = \"-----\"\n",
        "guardian_articles = []\n",
        "page = 1\n",
        "\n",
        "while len(guardian_articles) < 250:\n",
        "    url = (\n",
        "        f\"https://content.guardianapis.com/search\"\n",
        "        f\"?api-key={API_KEY}&page-size=50&page={page}&show-fields=bodyText\"\n",
        "    )\n",
        "    r = requests.get(url)\n",
        "    data = r.json()\n",
        "\n",
        "    for result in data['response']['results']:\n",
        "        text = result['fields'].get('bodyText', '')\n",
        "        if text and len(text) > 300:\n",
        "            guardian_articles.append(text)\n",
        "            print(f\"Guardian: {len(guardian_articles)} статей собрано.\")\n",
        "            if len(guardian_articles) >= 250:\n",
        "                break\n",
        "    page += 1\n",
        "    time.sleep(1)\n",
        "\n",
        "# Сохраняем\n",
        "with open(\"guardian_articles.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for article in guardian_articles:\n",
        "        f.write(article + \"\\n\" + \"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка текста и очистка данных\n",
        "with open(\"news_corpus.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "# Разбиваем по разделителю строк\n",
        "raw_articles = raw_text.split(\"================================================================================\") # вот такой вот странный разделитесь у меня в датасете\n",
        "\n",
        "# Убираем теги [BBC], [Guardian], пустые строки и пробелы\n",
        "cleaned_articles = []\n",
        "for article in raw_articles:\n",
        "    # Удаляем лишние теги\n",
        "    article = article.replace(\"[BBC]\", \"\").replace(\"[Guardian]\", \"\").strip()\n",
        "    if article:\n",
        "        cleaned_articles.append(article)\n",
        "\n",
        "# Проверим результат\n",
        "print(f\"Количество статей: {len(cleaned_articles)}\")\n",
        "print(\"Пример статьи:\", cleaned_articles[0][:500])  # первые 500 символов первой статьи"
      ],
      "metadata": {
        "id": "ETnACl0gSHMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ae7c4e-df9a-44d6-e3d1-426f85aed54f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество статей: 500\n",
            "Пример статьи: This week's G7 summit in Canada will be dominated by war - only not one of those that the world leaders had expected. High on the agenda had been Russia's war against Ukraine and Donald Trump's tariff war against America's trading partners. Instead the three-day gathering in the Rocky Mountains of Alberta will inevitably be focused on war in the Middle East. Israel's decision to attack Iran will force the Group of Seven western powers to spend less time on other issues and instead discuss ways o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Каждую статью разбиваю на отдельные предложения\n",
        "sentences = []\n",
        "for article in cleaned_articles:\n",
        "    sents = re.split(r'[.!?]', article)\n",
        "    sents = [s.strip().lower() for s in sents if len(s.strip()) > 10]\n",
        "    sentences.extend(sents)"
      ],
      "metadata": {
        "id": "DPYWrG96ZVGn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Токенизация и подготовка данных\n",
        "vocab_size = 4000 # создадим словарь на 4000 наиболее часто встречающихся слов\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\") # все неизвестные слова заменим на out-of-vocabulary\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "# Создание обучающих последовательностей\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "max_seq_len = 20 # размер входной последовательности\n",
        "X, y = [], []\n",
        "\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        n_gram = seq[max(0, i - max_seq_len):i+1]\n",
        "        X.append(n_gram[:-1])\n",
        "        y.append(n_gram[-1])\n",
        "\n",
        "X = pad_sequences(X, maxlen=max_seq_len) # заполняем недостающие позиции слева\n",
        "y = np.array(y)  # просто массив целых меток\n",
        "\n",
        "print(f\"Тренировочные сэмплы: {len(X)}\")\n",
        "\n",
        "#  Создание и компиляция модели\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_seq_len))\n",
        "model.add(LSTM(100)) # из-за ограниченной RAM взяла 100, т.к. на 150 уже не справлялось\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "nIsz8et8ZYBi",
        "outputId": "46fd295e-ec5b-448e-8ed6-dba5c490d8fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тренировочные сэмплы: 521398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, batch_size=64, epochs=15, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icM7XxCyZzDt",
        "outputId": "dc73e793-2a2d-4409-d6d5-954e1f6f4173"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 52ms/step - accuracy: 0.1581 - loss: 5.8780\n",
            "Epoch 2/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 49ms/step - accuracy: 0.1914 - loss: 5.1538\n",
            "Epoch 3/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 50ms/step - accuracy: 0.2066 - loss: 4.8649\n",
            "Epoch 4/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 50ms/step - accuracy: 0.2168 - loss: 4.6958\n",
            "Epoch 5/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 49ms/step - accuracy: 0.2244 - loss: 4.5634\n",
            "Epoch 6/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 49ms/step - accuracy: 0.2309 - loss: 4.4592\n",
            "Epoch 7/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 50ms/step - accuracy: 0.2362 - loss: 4.3727\n",
            "Epoch 8/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 50ms/step - accuracy: 0.2418 - loss: 4.2939\n",
            "Epoch 9/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 50ms/step - accuracy: 0.2454 - loss: 4.2339\n",
            "Epoch 10/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 49ms/step - accuracy: 0.2491 - loss: 4.1784\n",
            "Epoch 11/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 49ms/step - accuracy: 0.2530 - loss: 4.1265\n",
            "Epoch 12/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 50ms/step - accuracy: 0.2554 - loss: 4.0855\n",
            "Epoch 13/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 48ms/step - accuracy: 0.2589 - loss: 4.0398\n",
            "Epoch 14/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 50ms/step - accuracy: 0.2632 - loss: 3.9999\n",
            "Epoch 15/15\n",
            "\u001b[1m8147/8147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 49ms/step - accuracy: 0.2658 - loss: 3.9611\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x791bf1a42650>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# посмотрим на наиболее часто встречающиеся 3-граммы, чтобы сформулировать стартовые фразы\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Пример: 3-граммы\n",
        "three_grams = []\n",
        "for sentence in sentences:\n",
        "    tokens = sentence.split()\n",
        "    three_grams.extend(ngrams(tokens, 3))\n",
        "\n",
        "common_3grams = Counter(three_grams).most_common(50)\n",
        "for grams, freq in common_3grams:\n",
        "    print(\" \".join(grams), \":\", freq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqokPa61g2va",
        "outputId": "450625a8-3dbe-4581-9827-b039ff10b158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one of the : 209\n",
            "a lot of : 142\n",
            "as well as : 130\n",
            "in the uk : 114\n",
            "the end of : 103\n",
            "part of the : 95\n",
            "according to the : 93\n",
            "some of the : 91\n",
            "said it was : 87\n",
            "over: south africa : 84\n",
            "said in a : 81\n",
            "told the bbc : 80\n",
            "in the middle : 79\n",
            "be able to : 79\n",
            "to be a : 77\n",
            "out of the : 76\n",
            "the middle east : 74\n",
            "in the first : 72\n",
            "a couple of : 72\n",
            "in the us : 70\n",
            "the trump administration : 70\n",
            "a number of : 64\n",
            "the white house : 63\n",
            "in a statement : 62\n",
            "there is a : 61\n",
            "it was a : 61\n",
            "for the first : 61\n",
            "the united states : 59\n",
            "going to be : 59\n",
            "the first time : 56\n",
            "this is a : 54\n",
            "there is no : 54\n",
            "sign up for : 54\n",
            "as part of : 53\n",
            "the number of : 51\n",
            "it is a : 51\n",
            "is one of : 50\n",
            "in the region : 49\n",
            "the university of : 49\n",
            "to make a : 48\n",
            "said he was : 48\n",
            "at the time : 48\n",
            "end of the : 46\n",
            "of the day : 45\n",
            "a series of : 44\n",
            "in the world : 44\n",
            "part of a : 44\n",
            "at the same : 43\n",
            "(target 282; markram : 43\n",
            "there was a : 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение модели\n",
        "model.save(\"rnn_news_generator.keras\")\n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "# Генерация текста\n",
        "def generate_text(seed_text, tokenizer, model, maxlen=20, num_words=50, temperature=1.0):\n",
        "    result = seed_text.lower()\n",
        "    for _ in range(num_words):\n",
        "        token_list = tokenizer.texts_to_sequences([result])[0]\n",
        "        token_list = token_list[-maxlen:]\n",
        "        token_list = pad_sequences([token_list], maxlen=maxlen)\n",
        "        prediction = model.predict(token_list, verbose=0)[0]\n",
        "\n",
        "        predicted_id = sample_with_temperature(prediction, temperature)\n",
        "        output_word = tokenizer.index_word.get(predicted_id, \"\")\n",
        "\n",
        "        if output_word == \"\" or output_word == \"<OOV>\":\n",
        "            continue  # пропускаем <OOV> или неизвестные слова\n",
        "\n",
        "        result += \" \" + output_word\n",
        "    return result\n",
        "\n",
        "# Составим стартовые фразы\n",
        "seed_phrases = [\n",
        "    \"the white house\", \"climate change is\", \"environmental issues\", \"the trump administration\",\n",
        "    \"the university of oxford researchers\", \"the prime minister said\", \"in the world\", \"the investigation revealed\", \"social media\"\n",
        "]\n",
        "\n",
        "for seed in seed_phrases:\n",
        "    print(f\"\\n Seed: \\\"{seed}\\\"\")\n",
        "    print(generate_text(seed, tokenizer, model, maxlen=30, num_words=50, temperature=0.8)) # с temperature=0.4 получались результаты далекие от смысла"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kVqHooRTBTe",
        "outputId": "fc2d7a93-4a53-41fb-852d-f062fa58253a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Seed: \"the white house\"\n",
            "the white house is also as the governor began writing that net zero tariffs has become a very different possibility that the us the president is he produced a source of the bill in reducing\n",
            "\n",
            " Seed: \"climate change is\"\n",
            "climate change is using interest in tax rises added the first scheme would be made for the face of the pandemic the patient and safety mail would sell sewage sludge on its climate crisis to deal with small\n",
            "\n",
            " Seed: \"environmental issues\"\n",
            "environmental issues in that time lords will also be a source of sustained bills to make it as it was done by the material be taken to be ruled out how to pay a screening health\n",
            "\n",
            " Seed: \"the trump administration\"\n",
            "the trump administration has become critical of the critical war in gaza as the us president the situation is going to join the new parade to the scale of the zionist regime and us intelligence facilities in the\n",
            "\n",
            " Seed: \"the university of oxford researchers\"\n",
            "the university of oxford researchers have only described the plane crash from the aid at the same care and the firm said the family law including patients have been criticised on the uk that is the best cause in the past building by a later\n",
            "\n",
            " Seed: \"the prime minister said\"\n",
            "the prime minister said the assault would make a deal with that there is a regular years of the technology and street on the hearing that history is the latest difference of the frontline climate are not a risk of the effects of the issue they’re not\n",
            "\n",
            " Seed: \"in the world\"\n",
            "in the world there was serious people that were helped by a general public inquiry into the firm to house which he admitted about his attacks during covid spread across the current us open for the indian state of a small group of a\n",
            "\n",
            " Seed: \"the investigation revealed\"\n",
            "the investigation revealed the payments of the greatest genius is getting success up to the nhs and have been access to sell a medical care but ms said says she had been waiting\n",
            "\n",
            " Seed: \"social media\"\n",
            "social media has pledged to take place in this country to target people and local health and while sales in may just take advantage of the floor she said the end that means their experience will stay in a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты генерации текста довольно интересные и в целом соответствуют ожидаемому качеству для RNN, обученной на сравнительно небольшом корпусе. Модель использует клише из новостей — это плюс, например, \"a medical care\", \"the critical war in gaza\", \"net zero tariffs\". Если же есть хорошее удержание контекста в начале предложения, то к концу уже нет. Конечно, это достаточно трудная задача особенно из-за специфичной лексики. Что можно улучшить, но Google Colab ограничивает."
      ],
      "metadata": {
        "id": "cvfv76MENmth"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}