{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09daa268-ae7f-4f4c-8ac9-629cdfabcdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World\n"
     ]
    }
   ],
   "source": [
    "# задаем функцию\n",
    "def greeting():\n",
    "    return'Hello, World'\n",
    "\n",
    "# вызываем функцию\n",
    "print(greeting())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca013f0-a429-4795-888b-22e35c69ff01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_sum(a,b):\n",
    "    return a + b \n",
    "calc_sum(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c1c197-34ef-478f-92df-d36eead1eb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'IS', 'a', 'sample', 'sentence']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text, cap=False, to_lower=True):\n",
    "  if cap == True:\n",
    "    text = text.capitalize()\n",
    "  if to_lower == True:\n",
    "    text = text.lower()\n",
    "  return text.split()\n",
    "\n",
    "tokenizer('this IS a sample sentence', to_lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03928eef-3ee0-4b83-9b56-984e2dba958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создать функцию с параметрами по умолчанию\n",
    "def say_hello(name, type_ ='standart'):\n",
    "  if type_ == \"standart\":\n",
    "    print(f'Hello {name}')\n",
    "  if type_ == \"friendly\":\n",
    "    print(f'Hello {name}! How are you?')\n",
    "  if type_ == \"star\":\n",
    "    print(f'Hello there, {name}!')\n",
    "say_hello('Олег', type_='star')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c452c5-c117-4358-8121-266eabdaaeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создать функцию с возвратом значения\n",
    "def add(a, b):\n",
    "  return a + b\n",
    "\n",
    "add(34, 78) #112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89bc8e-f474-42f2-8953-ff6776cd24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(a,b):\n",
    "    return a ** b\n",
    "\n",
    "power(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac81a5-a6bb-4cb7-9a4c-071dc484d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_say_hello(username,type='standart'):\n",
    "    if type=='standart':\n",
    "        print(f\"hello, {username}!\")\n",
    "    if type=='friendly':\n",
    "        print(f\"hello, {username}! what a great day to learn Python\")\n",
    "    if type=='starwars':\n",
    "        print(f\"hello there, {username}!\")\n",
    "name_say_hello('Jonh',type='friendly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d16c6c-c47d-4eee-ad86-1bca6dac79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_text(text):\n",
    "    word_list = []\n",
    "    symbol_list = []\n",
    "    for word in text:\n",
    "        word_tokens = text.split()\n",
    "        word_list.append(word_tokens)\n",
    "        break\n",
    "    print(word_list)\n",
    "tokenized_text('it was hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f72dec-0f95-44b0-93dc-1fbae74f2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' I like cake'\n",
    "latr = list(text)\n",
    "print(latr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa55d0f6-2d4a-49ad-8d02-0e2283811f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['во',\n",
       " 'поле',\n",
       " 'береза',\n",
       " '-',\n",
       " 'стояла,',\n",
       " 'румянная',\n",
       " 'стояла,',\n",
       " 'ай',\n",
       " 'люли',\n",
       " 'люли',\n",
       " 'стояла!',\n",
       " 'swag',\n",
       " '777']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenized(text, mode='word', regist=False, punct=3):\n",
    "            \n",
    "        if regist == True:\n",
    "            text=text.lower()\n",
    "\n",
    "        if punct==1:\n",
    "            text = re.sub(r'[^\\w\\s]',' ',text)\n",
    "        if punct==2:\n",
    "            text=re.sub(r'[^a-zA-Z0-9.,?!]',' ',text)\n",
    "        if punct==3:\n",
    "            text=text\n",
    "        return text.split() if mode == 'word' else list(text)\n",
    "tokenized(\"'\", 'word', True, punct = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83e75346-67f4-49e8-8040-1dcdb4cb6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1452a891-dd62-4a09-9655-b7826e1afaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LEMMAS': ['I',\n",
       "  'be',\n",
       "  'free',\n",
       "  ',',\n",
       "  'he',\n",
       "  'want',\n",
       "  'to',\n",
       "  'be',\n",
       "  'like',\n",
       "  'you',\n",
       "  ',',\n",
       "  'I',\n",
       "  'be',\n",
       "  'Michael',\n",
       "  'Jackson'],\n",
       " 'POS': [('I', 'PRON'),\n",
       "  ('am', 'AUX'),\n",
       "  ('free', 'ADJ'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('he', 'PRON'),\n",
       "  ('wants', 'VERB'),\n",
       "  ('to', 'PART'),\n",
       "  ('be', 'AUX'),\n",
       "  ('like', 'ADP'),\n",
       "  ('you', 'PRON'),\n",
       "  (',', 'PUNCT'),\n",
       "  ('I', 'PRON'),\n",
       "  ('am', 'AUX'),\n",
       "  ('Michael', 'PROPN'),\n",
       "  ('Jackson', 'PROPN')],\n",
       " 'NER': [(Michael Jackson, 'PERSON')]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def marking(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")  # Load a spaCy model\n",
    "    doc = nlp(text)\n",
    "\n",
    "    lemmas = []\n",
    "    pos = []\n",
    "    ner = []\n",
    "    result = dict()\n",
    "    \n",
    "    for token in doc:\n",
    "        lemmas.append(token.lemma_)\n",
    "        \n",
    "    for token in doc:\n",
    "        pos.append((token.text, token.pos_))\n",
    "\n",
    "    ner = [(ent, ent.label_) for ent in doc.ents]\n",
    "\n",
    "\n",
    "    result['LEMMAS'] = lemmas\n",
    "    result['POS'] = pos\n",
    "    result['NER'] = ner\n",
    "    \n",
    "    return result\n",
    "\n",
    "marking('I am free, he wants to be like you, I am Michael Jackson ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd7a31-3139-426d-9d1c-a5607b92937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "wn.synonyms('car')\n",
    "[['auto', 'automobile', 'machine', 'motorcar'], ['railcar', 'railroad_car', 'railway_car'], ['gondola'], ['elevator_car'], ['cable_car']]\n",
    ">>> wn.synonyms('coche', lang='spa')\n",
    "[['auto', 'automóvil', 'carro', 'máquina', 'turismo', 'vehículo'], ['automotor', 'vagón'], ['vagón', 'vagón_de_pasajeros']]\n",
    "Synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a80aebe2-6f62-4488-8bc5-10b418879d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kind',\n",
       " 'sort',\n",
       " 'form',\n",
       " 'variety',\n",
       " 'kind',\n",
       " 'kind',\n",
       " 'genial',\n",
       " 'kind',\n",
       " 'tolerant']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def synonyms(word):\n",
    "  syn_list = []\n",
    "\n",
    "  for syn in wordnet.synsets(word):\n",
    "    for lemma in syn.lemmas():\n",
    "      syn_list.append(lemma.name())\n",
    "\n",
    "  return syn_list\n",
    "\n",
    "synonyms('kind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e99b173-e522-4cf9-8be6-7bcb648549f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Elena\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['goodness',\n",
       " 'goodness',\n",
       " 'commodity',\n",
       " 'trade_good',\n",
       " 'full',\n",
       " 'estimable',\n",
       " 'honorable',\n",
       " 'respectable',\n",
       " 'beneficial',\n",
       " 'just',\n",
       " 'upright',\n",
       " 'adept',\n",
       " 'expert',\n",
       " 'practiced',\n",
       " 'proficient',\n",
       " 'skillful',\n",
       " 'skilful',\n",
       " 'dear',\n",
       " 'near',\n",
       " 'dependable',\n",
       " 'safe',\n",
       " 'secure',\n",
       " 'right',\n",
       " 'ripe',\n",
       " 'well',\n",
       " 'effective',\n",
       " 'in_effect',\n",
       " 'in_force',\n",
       " 'serious',\n",
       " 'sound',\n",
       " 'salutary',\n",
       " 'honest',\n",
       " 'undecomposed',\n",
       " 'unspoiled',\n",
       " 'unspoilt',\n",
       " 'well',\n",
       " 'thoroughly',\n",
       " 'soundly']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def find_synonym(word):\n",
    "    list_of_synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.name() != word:\n",
    "                list_of_synonyms.append(lemma.name())\n",
    "    return list_of_synonyms\n",
    "    \n",
    "find_synonym('good')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
